{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the edit distance representation\n",
    "def get_edit_distance_repr(components, blend):\n",
    "    add=False\n",
    "    output=[]\n",
    "    for c in difflib.ndiff(components, blend):\n",
    "        if c[0]=='-':\n",
    "            output.append('D')\n",
    "        elif c[0]=='+':\n",
    "            add = True\n",
    "            output.append(c[1:].strip())\n",
    "        else:\n",
    "            output.append('C')\n",
    "    return ''.join(output), add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the string from the edit distance encoding\n",
    "def get_from_copy_edit(example, copyedits):\n",
    "    output_str=[]\n",
    "    for i,s in enumerate(list(example)):\n",
    "        if copyedits[i] == 'C':\n",
    "            output_str.append(s)\n",
    "    return u''.join(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the evaluation scores\n",
    "def get_scores(gold_preds_file, output_preds_file):\n",
    "    gold_preds=[]\n",
    "    for l in open(gold_preds_file):\n",
    "        gold_preds.append(l.strip().split(':')[-1])\n",
    "        \n",
    "    output_preds=[]\n",
    "    for l in open(output_preds_file):\n",
    "        output_preds.append(l.strip().split(':')[-1])\n",
    "    print(gold_preds[:10], output_preds[:10])\n",
    "    edit_scores=[Levenshtein.distance(str(p),str(g)) for p, g in zip(output_preds, gold_preds) if g in gold_preds_ours]\n",
    "    dfrecs=[(p, g, Levenshtein.distance(str(p),str(g))) for p, g in zip(output_preds, gold_preds) if g in gold_preds_ours]\n",
    "    dfr=pd.DataFrame().from_records(dfrecs, columns=['p','g','d'])\n",
    "    print(\"Mean Edit Distance\", np.mean(edit_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/blends_cmu.txt', header=None, names=['word','c1','c2','dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf=pd.read_csv('./data/components-blends-blind.csv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_preds_ours=[get_from_copy_edit(s, t) for s, t in zip(bdf.source.values, bdf.target.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_preds_ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_set=set(df[df.dataset=='other'].word.values) - set(df[df.dataset=='knight'].word.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best forward (Exhaustive decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shopathon', 'fashism', 'brick', 'wikiquette', 'alternawhore', 'companding', 'clownsident', 'enculturement', 'carjack', 'diamat'] ['shopparathon', 'fashism', 'brickberry', 'wikiquette', 'alternore', 'companding', 'clowident', 'enlulture', 'carjack', 'dialerialism']\n",
      "Mean Edit Distance 1.7675925925925926\n"
     ]
    }
   ],
   "source": [
    "get_scores(\"./data/best_blind_forward_gangal_gold.txt\", \"./data/best_blind_forward_gangal_preds.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best backward (Exhaustive decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shopathon', 'fashism', 'brick', 'wikiquette', 'alternawhore', 'companding', 'clownsident', 'enculturement', 'carjack', 'diamat'] ['shoathon', 'fashism', 'brickberry', 'wiquette', 'alterhore', 'comprexpanding', 'closident', 'enlighture', 'carjack', 'dialerialism']\n",
      "Mean Edit Distance 1.7787037037037037\n"
     ]
    }
   ],
   "source": [
    "get_scores(\"./data/best_blind_backward_gangal_gold.txt\", \"./data/best_blind_backward_gangal_preds.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knight's FST Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Edit Distance 2.1076066790352503\n"
     ]
    }
   ],
   "source": [
    "aliya=pd.read_csv(\"./data/dataAliyaScraped_exact.csv\", header=None, names=[\"w1\", \"w2\", \"pred\"], sep=' ')\n",
    "joint_words=[w1+'}'+w2 for w1,w2 in zip(aliya.w1.values, aliya.w2.values)]\n",
    "aliya[\"full\"]=joint_words\n",
    "aliya=aliya[aliya.full.isin(set(bdf.source.values))]\n",
    "bdf[\"full\"]=bdf[\"source\"]\n",
    "bdf[\"gold_preds\"]=gold_preds_ours\n",
    "aliya=aliya.merge(bdf, on='full')\n",
    "edit_scores=[Levenshtein.distance(str(p),str(g)) for p, g in zip(aliya.pred.values, aliya.gold_preds.values) if g in gold_preds_ours]\n",
    "print(\"Baseline Edit Distance\", np.mean(edit_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
