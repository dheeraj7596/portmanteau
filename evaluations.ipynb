{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.call(\"python lstm.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "import numpy as np\n",
    "from sentence_getter import SentenceGetter\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras import optimizers\n",
    "import kenlm\n",
    "\n",
    "\n",
    "\n",
    "def get_model(max_len, n_words, n_tags, embedding_mat):\n",
    "    input = Input(shape=(max_len,))\n",
    "    model = Embedding(input_dim=n_words, weights=[embedding_mat], output_dim=50, input_length=max_len)(input)\n",
    "    model = Dropout(0.1)(model)\n",
    "    model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "    out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  # softmax output layer\n",
    "    model = Model(input, out)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_embedding_matrix(embeddings_path, word2idx):\n",
    "    embedding_vectors = {}\n",
    "    with open(embeddings_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line_split = line.strip().split(\" \")\n",
    "            vec = np.array(line_split[1:], dtype=float)\n",
    "            char = line_split[0]\n",
    "            embedding_vectors[char] = vec\n",
    "\n",
    "    embedding_matrix = np.zeros((len(word2idx), 50))\n",
    "    for char in word2idx:\n",
    "        embedding_vector = embedding_vectors.get(char)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word2idx[char]] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def get_word(X, y, words, tags):\n",
    "    ans = \"\"\n",
    "    for i, ch in enumerate(X):\n",
    "        if tags[y[i]] == \"C\":\n",
    "            ans += words[ch]\n",
    "    return ans\n",
    "\n",
    "def get_word2(word,tag_seq, words):\n",
    "    ans = \"\"\n",
    "    for i in range(len(word)):\n",
    "        if tag_seq[i]=='C':\n",
    "            ans+=words[word[i]]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"./data/df_lstm.pkl\", \"rb\"))\n",
    "embeddings_path = \"./data/pretrained_char_emb.txt\"\n",
    "\n",
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"$\")\n",
    "n_words = len(words)\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "tags.append(\"O\")\n",
    "n_tags = len(tags)\n",
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences\n",
    "max_len = 30\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "\n",
    "embedding_mat = get_embedding_matrix(embeddings_path, word2idx)\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words - 1)\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# 1.74 ,1.37 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([*X_tr,*X_tr,*X_tr,*X_tr])\n",
    "Y_train = [*y_tr,*y_tr,*y_tr,*y_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1194 samples, validate on 133 samples\n",
      "Epoch 1/5\n",
      "1194/1194 [==============================] - 4s 3ms/step - loss: 0.0953 - accuracy: 0.8009 - val_loss: 0.0625 - val_accuracy: 0.8669\n",
      "Epoch 2/5\n",
      "1194/1194 [==============================] - 3s 2ms/step - loss: 0.0609 - accuracy: 0.8740 - val_loss: 0.0480 - val_accuracy: 0.9025\n",
      "Epoch 3/5\n",
      "1194/1194 [==============================] - 3s 2ms/step - loss: 0.0519 - accuracy: 0.8910 - val_loss: 0.0450 - val_accuracy: 0.9023\n",
      "Epoch 4/5\n",
      "1194/1194 [==============================] - 3s 2ms/step - loss: 0.0485 - accuracy: 0.8975 - val_loss: 0.0442 - val_accuracy: 0.9040\n",
      "Epoch 5/5\n",
      "1194/1194 [==============================] - 3s 2ms/step - loss: 0.0476 - accuracy: 0.8979 - val_loss: 0.0432 - val_accuracy: 0.9080\n"
     ]
    }
   ],
   "source": [
    "model = get_model(max_len, n_words, n_tags, embedding_mat)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=5, validation_split=0.1, verbose=1)\n",
    "lmodel = kenlm.Model('./data/wordlist_english_filtered_threshold100-kenlm.arpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.568528618900828"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kenlm\n",
    "mod = kenlm.LanguageModel('./data/wordlist_english_filtered_threshold100-kenlm.arpa')\n",
    "mod.score(\"a s d e f e\")/6**0.5\n",
    "mod.score(\"a p p l e\")/5**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3581081081081081\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "true = []\n",
    "for i, test in enumerate(X_te):\n",
    "    p = model.predict(np.array([X_te[i]]))\n",
    "    t = y_te[i]\n",
    "    predictions = getTopk(p[0],10)\n",
    "    candidates = [get_word2(X_te[i],d[1], words) for d in predictions]\n",
    "    m_scores=[lmodel.score(\" \".join(c))/(float(len(\" \".join(c)))) for c in candidates]\n",
    "    for j in range(len(m_scores)):\n",
    "        m_scores[j]= m_scores[j]/6 +  predictions[j][0]\n",
    "#     max_idx =\n",
    "#     print(m_scores)\n",
    "    max_idx=-1\n",
    "    max_val = -99999\n",
    "    for ele in enumerate(m_scores):\n",
    "        if ele[1]>max_val:\n",
    "            max_val = ele[1]\n",
    "            max_idx = ele[0]\n",
    "#     max_idx=0\n",
    "    preds.append(candidates[max_idx])\n",
    "#     p = np.argmax(p, axis=-1)\n",
    "    t = np.argmax(t, axis=-1)\n",
    "#     preds.append(get_word(X_te[i], p[0], words, tags))\n",
    "    true.append(get_word(X_te[i], t, words, tags))\n",
    "\n",
    "distance = 0\n",
    "for i,word in enumerate(true):\n",
    "    distance += Levenshtein.distance(word, preds[i])\n",
    "print(distance / len(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "            \n",
    "def updatestr(s,i,ch):  \n",
    "    list1 = list(s)\n",
    "    list1[i] = ch\n",
    "    str1 = ''.join(list1)\n",
    "    return str1\n",
    "\n",
    "def getTopk(m,k):\n",
    "    mapping = {0:'D',1:'C',2:'O'}\n",
    "    r_mapping = {'D':0, 'C':1, 'O':2}\n",
    "#     prob_best = defaultdict(float)\n",
    "#     prob_second = defaultdict(float)\n",
    "#     assign(m,prob_best,prob_second)\n",
    "#     padding = 29\n",
    "#     results = []\n",
    "#     while prob_best[padding][0] == 'O':\n",
    "#         padding-=1\n",
    "#     seq_len = padding+1\n",
    "#     print(\"len \",seq_len)\n",
    "#     if padding>21:\n",
    "#         print(\"this one is gonna take time! Length = \", seq_len)\n",
    "#     best_seq = \"\"\n",
    "#     best_prob = 1.0\n",
    "#     for ele in prob_best:\n",
    "#         best_seq += prob_best[ele][0]\n",
    "#         best_prob *= prob_best[ele][1]\n",
    "    best_seq = \"\"\n",
    "    best_prob = 1.0\n",
    "    best_idx = np.argmax(m, axis=-1)\n",
    "    for i in range(30):\n",
    "        best_seq += mapping[best_idx[i]]\n",
    "        best_prob *= m[i][best_idx[i]]\n",
    "    heap = [(-1*best_prob,best_seq)]\n",
    "    heapq.heapify(heap)\n",
    "    \n",
    "    result = []\n",
    "    added = set()\n",
    "    while k>0:\n",
    "        top = heapq.heappop(heap)\n",
    "        result += [(top[0]*-1,top[1])]\n",
    "        added.add(top[1])\n",
    "        k-=1\n",
    "        prob = -1*top[0]\n",
    "        seq = top[1]\n",
    "        curr_prob = prob\n",
    "        curr_seq = seq\n",
    "        for i in range(30):\n",
    "            for j in range(3):\n",
    "                curr_seq = updatestr(curr_seq,i,mapping[j])\n",
    "                if curr_seq in added:\n",
    "                    continue\n",
    "                curr_prob = prob*m[i][j]/m[i][r_mapping[seq[i]]]\n",
    "                heapq.heappush(heap,(-1*curr_prob,curr_seq))\n",
    "                curr_seq = seq\n",
    "#     num = 1<<seq_len\n",
    "#     for i in range(num):\n",
    "#         seq = format(i, '040b')[-seq_len:]\n",
    "#         curr_prob = 1.0\n",
    "#         idx=0\n",
    "#         out_str = \"\"\n",
    "#         for ele in seq:\n",
    "#             if ele=='1':\n",
    "#                 curr_prob *= prob_best[idx][1]\n",
    "#                 out_str = out_str + prob_best[idx][0]\n",
    "#             else:\n",
    "#                 curr_prob *= prob_second[idx][1]\n",
    "#                 out_str = out_str + prob_second[idx][0]\n",
    "#             idx+=1\n",
    "        \n",
    "#         results += [(curr_prob, out_str.ljust(30, 'O'))]\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.04165565675043418, 'CCCCDDDDDCCCCCOOOOOOOOOOOOOOOO'),\n",
       " (0.030473228490919164, 'CCCDDDDDDCCCCCOOOOOOOOOOOOOOOO'),\n",
       " (0.023312213915672144, 'CCCCCDDDDCCCCCOOOOOOOOOOOOOOOO'),\n",
       " (0.019885439599809495, 'CCCCDDDDCCCCCCOOOOOOOOOOOOOOOO'),\n",
       " (0.017054068443514772, 'CCCDCDDDDCCCCCOOOOOOOOOOOOOOOO'),\n",
       " (0.017054068443514772, 'CCCDCDDDDCCCCCOOOOOOOOOOOOOOOO'),\n",
       " (0.014683610774561463, 'CCCCDDDDDDCCCCOOOOOOOOOOOOOOOO'),\n",
       " (0.014547208994875608, 'CCCDDDDDCCCCCCOOOOOOOOOOOOOOOO'),\n",
       " (0.014547208994875606, 'CCCDDDDDCCCCCCOOOOOOOOOOOOOOOO'),\n",
       " (0.012358366784220696, 'CCDCDDDDDCCCCCOOOOOOOOOOOOOOOO')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTop10(grr,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0527074e-01, 8.9458370e-01, 1.4553506e-04],\n",
       "       [1.5765575e-01, 8.4221870e-01, 1.2547441e-04],\n",
       "       [2.2877818e-01, 7.7112985e-01, 9.1942944e-05],\n",
       "       [4.2245165e-01, 5.7747412e-01, 7.4239564e-05],\n",
       "       [6.4114231e-01, 3.5880953e-01, 4.8188060e-05],\n",
       "       [8.8727862e-01, 1.1269377e-01, 2.7648372e-05],\n",
       "       [9.9155384e-01, 8.4371623e-03, 8.9927480e-06],\n",
       "       [8.5765886e-01, 1.4226426e-01, 7.6855402e-05],\n",
       "       [6.7675102e-01, 3.2306516e-01, 1.8384511e-04],\n",
       "       [2.6054394e-01, 7.3913217e-01, 3.2386402e-04],\n",
       "       [2.1751241e-01, 7.8128552e-01, 1.2020216e-03],\n",
       "       [1.2100350e-01, 8.7761891e-01, 1.3776020e-03],\n",
       "       [1.0943196e-01, 8.7928015e-01, 1.1287919e-02],\n",
       "       [6.5070033e-02, 9.0963250e-01, 2.5297526e-02],\n",
       "       [9.3023311e-03, 3.7080593e-02, 9.5361710e-01],\n",
       "       [1.3950175e-03, 5.8074510e-03, 9.9279755e-01],\n",
       "       [3.6855845e-04, 1.9973603e-03, 9.9763405e-01],\n",
       "       [1.3010575e-04, 1.0026451e-03, 9.9886727e-01],\n",
       "       [5.8977057e-05, 6.1481359e-04, 9.9932623e-01],\n",
       "       [3.6356923e-05, 4.3648828e-04, 9.9952722e-01],\n",
       "       [2.9294171e-05, 3.4942085e-04, 9.9962127e-01],\n",
       "       [2.8409553e-05, 3.0896580e-04, 9.9966264e-01],\n",
       "       [3.1305328e-05, 2.9775151e-04, 9.9967098e-01],\n",
       "       [3.7887439e-05, 3.1007623e-04, 9.9965203e-01],\n",
       "       [4.9380946e-05, 3.4720267e-04, 9.9960345e-01],\n",
       "       [6.8506146e-05, 4.1698135e-04, 9.9951446e-01],\n",
       "       [1.0027256e-04, 5.3637958e-04, 9.9936336e-01],\n",
       "       [1.5353858e-04, 7.3833030e-04, 9.9910814e-01],\n",
       "       [2.4401782e-04, 1.0879177e-03, 9.9866807e-01],\n",
       "       [3.9990136e-04, 1.7202521e-03, 9.9787986e-01]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}