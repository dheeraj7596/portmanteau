{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from io import open\n",
    "%matplotlib inline\n",
    "import Levenshtein\n",
    "import seaborn as sns\n",
    "import pylab as pl\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_syllables(v):\n",
    "    vowels=set(['AA','AE','AH','AO','AW','AY','EH','ER','EY','IH','IY','OW','OY','UH','UW'])\n",
    "    phonemes=v.split(' ')\n",
    "    cv=0\n",
    "    for p in phonemes:\n",
    "        if p in vowels:\n",
    "            cv=cv+1\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_helper(v, num_syllables=2, ctype='BACK'):\n",
    "    vowels=set(['AA','AE','AH','AO','AW','AY','EH','ER','EY','IH','IY','OW','OY','UH','UW'])\n",
    "    phonemes=v.split(' ')        \n",
    "    cv=0\n",
    "    output=[]\n",
    "    if ctype=='BACK':\n",
    "        for p in phonemes:\n",
    "            if p in vowels:\n",
    "                cv=cv+1\n",
    "                if cv > num_syllables:\n",
    "                    break\n",
    "            output.append(p)\n",
    "    elif ctype == 'FORE':\n",
    "        phonemes_v=' '.join(phonemes[::-1])\n",
    "        cp = clip_helper(phonemes_v, num_syllables, ctype='BACK')\n",
    "        output = cp.split(' ')[::-1]\n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(v, num_syllables=2):\n",
    "    vowels=set(['AA','AE','AH','AO','AW','AY','EH','ER','EY','IH','IY','OW','OY','UH','UW'])\n",
    "    phonemes=v.split(' ')\n",
    "    ctype=global_pmf.sample()\n",
    "    if '@' in v: # compound clippins\n",
    "        part1=v.split('@')[0]\n",
    "        part2=v.split('@')[1]\n",
    "        part1_phonemes = part1.strip().split(' ')\n",
    "        part2_phonemes = part2.strip().split(' ')\n",
    "        part1_clip=clip_helper(' '.join(part1_phonemes), num_syllables=1)\n",
    "        part2_clip=clip_helper(' '.join(part2_phonemes), num_syllables=1)\n",
    "        assert '@' not in part1_clip\n",
    "        assert '@' not in part2_clip\n",
    "        return part1_clip + ' ' + part2_clip\n",
    "    else:\n",
    "        return clip_helper(v, num_syllables, ctype=ctype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_num_syllables_clipping(v):\n",
    "    return int(ml.predict(v)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_clip(v, num_syllables=2):\n",
    "    vowels=set(['AA','AE','AH','AO','AW','AY','EH','ER','EY','IH','IY','OW','OY','UH','UW'])\n",
    "    v=v.replace('@',' ')\n",
    "    phonemes=v.split(' ')\n",
    "    keep_length=np.random.randint(1, len(v)+1)\n",
    "    return ' '.join(phonemes[:keep_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class Pmf(Counter):\n",
    "    \"\"\"A Counter with probabilities.\"\"\"\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"Normalizes the PMF so the probabilities add to 1.\"\"\"\n",
    "        total = float(sum(self.values()))\n",
    "        for key in self:\n",
    "            self[key] /= total\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"Adds two distributions.\n",
    "\n",
    "        The result is the distribution of sums of values from the\n",
    "        two distributions.\n",
    "\n",
    "        other: Pmf\n",
    "\n",
    "        returns: new Pmf\n",
    "        \"\"\"\n",
    "        pmf = Pmf()\n",
    "        for key1, prob1 in self.items():\n",
    "            for key2, prob2 in other.items():\n",
    "                pmf[key1 + key2] += prob1 * prob2\n",
    "        return pmf\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"Returns an integer hash value.\"\"\"\n",
    "        return id(self)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self is other\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Returns values and their probabilities, suitable for plotting.\"\"\"\n",
    "        return zip(*sorted(self.items()))\n",
    "    \n",
    "    def sample(self):\n",
    "        keys, vals= zip(*self.items())\n",
    "        return np.random.choice(keys, p=vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_phonemes(p):\n",
    "    return len(p.replace('@',' ').split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_syll_score(row):\n",
    "    if '@' in row.word:\n",
    "        return row.tedit\n",
    "    if row.pred_num_syll==1:\n",
    "        return row.oedit\n",
    "    else:\n",
    "        return row.tedit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edit_distances_grapheme(row):\n",
    "    return Levenshtein.distance(row.clipping, row.goldgrapheme), Levenshtein.distance(row.clipping, row.rand), Levenshtein.distance(row.clipping, row.one), Levenshtein.distance(row.clipping, row.two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orecs=[]\n",
    "f = open('./data/clippings_analysis.txt')\n",
    "for l in f:\n",
    "    tokens=l.strip().split(' ')\n",
    "    orecs.append((tokens[0], u' '.join(tokens[1:]).strip()))\n",
    "df=pd.DataFrame().from_records(orecs, columns=['clipping','full'])\n",
    "df_clipping_only=pd.read_csv('./data/only_clippings_gold.phonemes', sep='\\t', skiprows=3, header=None, names=['word','phonemes'])\n",
    "df_clipping_only[\"num\"]=[get_num_syllables(ps) for ps in df_clipping_only.phonemes.values] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_components_only=pd.read_csv('./data/only_clippings_full_components_gold.phonemes', sep='\\t', skiprows=3, header=None, names=['word','phonemes'])\n",
    "df_components_only[\"num\"]=[get_num_syllables(ps) for ps in df_components_only.phonemes.values] \n",
    "global_pmf=Pmf(Counter({'BACK':305,'FORE':83,'COMPOUND':0}))\n",
    "global_pmf.normalize()\n",
    "df_components_only[\"comp_phonemes_len\"]=df_components_only.phonemes.apply(get_num_phonemes)\n",
    "df_clipping_only[\"clipping_phonemes_len\"]=df_clipping_only.phonemes.apply(get_num_phonemes)\n",
    "syllable_counter_clippings=Counter(df_clipping_only.num.values)\n",
    "syllable_counter_clippings_pmf = Pmf(syllable_counter_clippings)\n",
    "syllable_counter_clippings_pmf.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the outputs of Random, 1-Syllable, 2-Syllable and Gold Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gold_clippings=df_clipping_only.word.values\n",
    "gold_graphemes=[line.strip() for line in open('./data/gold_clipping_for_p2g_new.graphemes').readlines()]\n",
    "rand_graphemes=[line.strip() for line in open('./data/rand_clipping_for_p2g_new.graphemes').readlines()]\n",
    "one_syl_graphemes=[line.strip() for line in open('./data/one_syl_clipping_for_p2g_new.graphemes').readlines()]\n",
    "two_syl_graphemes=[line.strip() for line in open('./data/two_syl_clipping_for_p2g_new.graphemes').readlines()]\n",
    "\n",
    "edf_recs=zip(df_components_only.word.values, gold_clippings, gold_graphemes, rand_graphemes, one_syl_graphemes, two_syl_graphemes)\n",
    "edf=pd.DataFrame().from_records(edf_recs, columns=['word','clipping','goldgrapheme','rand','one','two'])\n",
    "edf=edf.astype(str)\n",
    "\n",
    "edf[\"gedit\"], edf[\"redit\"], edf[\"oedit\"], edf[\"tedit\"]= zip(*edf.apply(get_edit_distances_grapheme, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_num_syll = [syllable_counter_clippings_pmf.sample() for i in np.arange(0, len(edf))]\n",
    "edf['min']=edf[['oedit','tedit']].min(axis=1)\n",
    "edf[\"pred_num_syll\"]=pred_num_syll\n",
    "edf[\"gscore\"]=edf.apply(get_global_syll_score, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Length model (ClipGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_length(v):\n",
    "    parts = v.split(' ')\n",
    "    if len(parts) > 1:\n",
    "        l=int(gm.predict(len(v))[0])\n",
    "        return parts[0][:(l/2)] + parts[1][:l/2]\n",
    "    else:\n",
    "        ctype=global_pmf.sample()\n",
    "        l=int(gm.predict(len(v))[0])\n",
    "        if ctype == 'BACK':\n",
    "            return v[:l]\n",
    "        elif ctype == 'FORE':\n",
    "            return v[-l:]\n",
    "\n",
    "def get_edit_distance_clip_length(row):\n",
    "    return Levenshtein.distance(row.clipping, row.cpleng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylengthdf=pd.DataFrame().from_records(zip(df_components_only.word.values,df_clipping_only.word, df_components_only.comp_phonemes_len.values, \n",
    "df_clipping_only.clipping_phonemes_len.values, df_clipping_only.num, df_components_only.num.values), columns=['word','clipping','comp_phonemes_len','clipping_phonemes_len', 'num', 'compnum'])\n",
    "mylengthdf[\"wlen\"]=mylengthdf.word.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "mylengthdf_train, mylengthdf_test= train_test_split(mylengthdf, train_size=0.7)\n",
    "x=mylengthdf_train[[\"wlen\"]].values\n",
    "y=mylengthdf_train[\"num\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after  2  iterations\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=7.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-6ff63dea0076>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0medf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cpleng\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# edf[\"cpeditg\"]=edf.apply(get_edit_distance_clip_length, axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3591\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-31db4dbcf57e>\u001b[0m in \u001b[0;36mclip_length\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mctype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobal_pmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mctype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'BACK'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, return_std)\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[0mStandard\u001b[0m \u001b[0mdeviation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpredictive\u001b[0m \u001b[0mdistribution\u001b[0m \u001b[0mof\u001b[0m \u001b[0mquery\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[0my_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_std\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0my_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coef_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    206\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    512\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    515\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=7.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "x_g=mylengthdf_train.word.apply(len).values\n",
    "y_g=mylengthdf_train.clipping.apply(len).values\n",
    "gm = BayesianRidge(verbose=True, compute_score=True, tol=0.0001)\n",
    "gm.fit(x_g.reshape(-1,1),y_g)\n",
    "edf[\"cpleng\"]=edf.word.apply(clip_length)\n",
    "# edf[\"cpeditg\"]=edf.apply(get_edit_distance_clip_length, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfm=edf[edf.word.isin(mylengthdf_test.word.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'cpeditg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-34d85d76224e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtredrecs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tedit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medfm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtedit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcredrecs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gscore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medfm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcredrecsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpeditg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medfm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpeditg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mcminrecs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cminrecs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medfm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medfm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"min\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mvdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgredrecs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrredrecs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0moredrecs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtredrecs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcredrecs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcredrecsg\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcminrecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'distance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'cpeditg'"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "gredrecs=zip(itertools.repeat('gedit', len(edfm)), edfm.gedit.values)\n",
    "rredrecs=zip(itertools.repeat('redit', len(edfm)), edfm.redit.values)\n",
    "oredrecs=zip(itertools.repeat('oedit', len(edfm)), edfm.oedit.values)\n",
    "tredrecs=zip(itertools.repeat('tedit', len(edfm)), edfm.tedit.values)\n",
    "credrecs=zip(itertools.repeat('gscore', len(edfm)), edfm.gscore.values)\n",
    "credrecsg=zip(itertools.repeat('cpeditg', len(edfm)), edfm.cpeditg.values)\n",
    "cminrecs=zip(itertools.repeat('cminrecs', len(edfm)), edfm[\"min\"].values)\n",
    "vdf=pd.DataFrame().from_records(gredrecs+rredrecs+oredrecs+tredrecs+credrecs+credrecsg+cminrecs, columns=['model','distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-946781797c31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'redit'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'oedit'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tedit'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gscore'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cminrecs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cpeditg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gedit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Naive'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ClipPhone-1Syl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ClipPhone-2Syl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ClipPhone'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ClipPhone(O)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ClipGraph'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'G2P-Gold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Edit Distance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./figs/clipping_edit_distance_all.pdf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vdf' is not defined"
     ]
    }
   ],
   "source": [
    "ax=sns.barplot(vdf.model, vdf.distance, order=['redit','oedit','tedit','gscore','cminrecs','cpeditg','gedit'])\n",
    "ax.set_xticklabels(['Naive','ClipPhone-1Syl','ClipPhone-2Syl','ClipPhone','ClipPhone(O)', 'ClipGraph','G2P-Gold'], fontsize=12, rotation=90)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Edit Distance', fontsize=12)\n",
    "pl.savefig('./figs/clipping_edit_distance_all.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
